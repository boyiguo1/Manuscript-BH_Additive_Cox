\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{lmodern}        % https://github.com/rstudio/rticles/issues/343
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}

\title{A scalable Cox proportional hazard additive model for survival
prediction and associated gene detection}

\author{
  }


% Pandoc citation processing
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
% for Pandoc 2.8 to 2.10.1
\newenvironment{cslreferences}%
  {}%
  {\par}
% For Pandoc 2.11+
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc} % for calculating minipage widths
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\begin{document}
\maketitle

\def\tightlist{}


\begin{abstract}
TODO: to add intrstruc
\end{abstract}

\keywords{
    Class file; \LaTeX; Statist. Med.; Rmarkdown;
  }

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Risk prediction. Sometimes simplies to a classification function. Look
through finer length via survival analysis.

While the survival analysis is based on linearity assumption where each
perdictor have linear effect on the predictive scale. There has been
efforts to relax the linear assumption, for example xxx xxx xxx.

Messages: 1. Easily generalized to partial linear structure or semi
parametric additive model in the Cox proportional Hazard model context
2. Clearification of the terminology (semiparametric model / Cox
additive model versus survival additive model)

-Omics, High-dimensional,

High-dimensional additive mode has been studied under the generalized
additive model

To the best of knowledge, there is yet efforts on studying bayesian
heiarchical models, particularaly the spike-and-slab lasso prior under
the high-dimensional additive model under Cox proportional hazard
paradigm. We ackowledge, there are other additive models for studying
survival outcomes. However, those model focus on studying the risk
differences instead of risk ratio, and hence have different utilities.

Significance: We are the firs to apply the spike-and-slab lasso prior in
the cox proportional hazard additive model paradigm

Purpose: improved prediction + Bi-level selection

\hypertarget{literature-review}{%
\subsection{Literature review}\label{literature-review}}

\begin{itemize}
\item
  Lin and Halabi (2013) reviewed curve interpolation in the context of
  Cox proportional hazard models, with the aims to provide alternatives
  to models with implicit linearity with regards to model specification
  and variable selection. The authors used synthetic data to evaluate
  the variable selection and predictive performance of the
  state-of-the-art (by 2013) linear and nonlinear Cox proportional
  hazard models, i.e.~COSSO, adaptive COSSO, LASSO, Adaptive LASSO.
  Despite the computation intensity of nonlinear (nonparametric) models,
  the authors suggests to compare the linear models and non-linear
  models to make assertion on which model is more appropriate.

  In the simulation, the authors examined high-dimensional problem where
  the author took a two-step strategy: screening + models. This strategy
  is a little bit surprising to me as the models can be directly applied
  to address the high dimension problem, even poorly. Overall, the
  article is very well written, and can be used as \textbf{a template
  for review/ evaluation articles}.
\end{itemize}

\hypertarget{cox-model}{%
\subsection{Cox Model}\label{cox-model}}

\begin{itemize}
\item
  Leng and Zhang (2006) is one among the earliest literature that
  expands nonparametric Cox models to the high-dimensional setting,
  where variable selection is of primary interests. The author applied
  component selection and smoothing operator method (COSSO) in the
  context of proportional hazard regression. The advantage of COSSO, in
  comparison to prior works say smoothing spline, is to shrink
  coefficients to be exactly zero, mirroring between LASSO and ridge
  regression. A gradient descent algorithm was provided for model
  fitting. The tuning of the model is achieved by selecting the
  smoothing parameter with the minimum approximate cross-validation
  score, a modification of cross-validation criterion. Another advantage
  of the proposed method is its ability to model effect of two variables
  as a surface, similar to ANOVA. The simulation considered a synthetic
  dataset with 8 variables, among which 5 are active (non-zero
  coefficient). Both correlation structure among predictors, censoring
  rate and sample size are considered.
\item
  Du, Ma, and Liang (2010) proposed another additive cox model with the
  focus on variable selection among parametric covariates, via sparse
  penalty, and smoothing of non-parametric additive functions, via
  smoothing penalty. The joint estimation of parametric coefficeints and
  smoothing function is achieved by an iterative two-step procedure,
  reciprocal maximization/minimization of likelihood functions
  conditioning on with assuming the parametric and non-parametric
  components from previous iteration respectively. Model selection is
  via a one-step approximation of the SCAD penalty for the parametric
  part of the model, and minimizing a proposed Kullback--Leibler ratio
  statistics for nonparametric part. The numerical studies examine the
  model performance under situations where sample size and censoring
  rate are the variables of RNG. In discussions, authors gives some
  directions where some extension of the current framework is possible.
\item
  Lian, Li, and Hu (2013) proposed an high-dimensional additive Cox
  model that uses SCAD penalties to selecting non-parametric component
  functions. An active-set-type algorithm was proposed for expedited
  model fitting compared to the classic local quadratic approximation
  algorithm. Tuning of the model is necessary where three parameters are
  considered: SCAD constant \(c\), the regulation parameter \(\lambda\),
  and variable size constraint \(M\). The author suggest that \(c=3.7\)
  following SCAD recommendation, with \(M\) to be specified based on
  assumption on variable size, and \(\lambda\) to be tuned and selected
  be information criteria, which include (AIC, BIC, EBIC).
  \textbf{Extensive} simulations had been done, studying different model
  selection criteria on model selection, and there is no consensus made.
  The author argued the potential of extending the model to
  semi-parametric Cox model, but didn't implement it. The authors also
  mentioned ``\emph{it is not clear whether and how high dimensionality
  will affect the estimation of the baseline hazard function},'' which
  can be an interesting question to follow up.
\item
  Yang et al. (2018) proposed the additive cox model specifically for
  high-dimensional data. Its primary aim is to screening the the
  predictors of the model. It expended the partial likelihood function
  using the Taylor's expansion where The first derivative and second
  derivative of the partial likelihood can be used as smooth and sparse
  penalties. The smoothing functions in this framework adapts B-spline,
  but I think it is possible to generalized to other member of the
  spline family. Sure screening property is proven.
\end{itemize}

\newpage

\hypertarget{cox-proportional-hazard-additive-model}{%
\section{Cox Proportional Hazard Additive
Model}\label{cox-proportional-hazard-additive-model}}

\newpage

\hypertarget{simulation-studies}{%
\section{Simulation Studies}\label{simulation-studies}}

The objective o fthe simulation studies is to examine the performance of
the proposed model under various settings, including different settings
of - sparsity, i.e.~number of active variables (whose effect is not zero
across covariate range) / total number of covariates included in the
model - sample size to number of variable ratio, - correlation
structures among the covariates when for identifiability purpose -
signal to noise ratio - mixture of additive functions - linear functions
- sin functions - quadrative functions - exponential functions

Particularly relavent to survival outcomes, in addition, we consider
various settings of censoring rate, underlying distributions of baseline
hazard function, which include commonly used familyes, Exponential,
Weibull, Gumptry

\hypertarget{while-the-primary-focus-of-the-this-simulation-studies-is-to-examine-the-predictive-performance-of-the-model-and-hence-we-select-the-followings-as-evaluation-metrics}{%
\subsection{While the primary focus of the this simulation studies is to
examine the predictive performance of the model, and hence, we select
the followings as evaluation
metrics:}\label{while-the-primary-focus-of-the-this-simulation-studies-is-to-examine-the-predictive-performance-of-the-model-and-hence-we-select-the-followings-as-evaluation-metrics}}

\begin{itemize}
\tightlist
\item
  Caliberation: as we know the \(\eta_i\) for the test data, hence, we
  can compare \(\eta_i\) with its estimate \(\hat \eta_i\) via mean
  squared function mean absolute function.
\item
  Discrimination: We use Uno etal's concordiance index. Even though
  Harrel's concordiance index is more popular, it suffers from bias when
  censoring presents.{[}Cite Rahman et al.~2017{]}
\end{itemize}

In each iteration of the simulation process, we independently generate
the training and testing datasets following the previously described
data generation process. We use the training dataset to construct each
model of comparison and find the `optimal` model using 10-fold
cross-validation. Then we use the fitted model to make prediction for
the testing dataset and calculate the evaluation metrics.

? How to validate the data generating process works

As some of the evaluation metrics are relative, we compare the
performance to a state-of-the-art survival model, which include - COSSO
- Adaptive COSSO (maybe) - group penalized models, group bayesian models

\newpage

\hypertarget{metabolites-data-analysis}{%
\section{Metabolites Data Analysis}\label{metabolites-data-analysis}}

\newpage

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

sdfadfs \newpage

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-Du2010}{}%
Du, Pang, Shuangge Ma, and Hua Liang. 2010. {``{Penalized variable
selection procedure for Cox models with semiparametric relative
risk}.''} \emph{Annals of Statistics} 38 (4): 2092--2117.
\url{https://doi.org/10.1214/09-AOS780}.

\leavevmode\hypertarget{ref-Leng2006}{}%
Leng, Chenlei, and Hao Helen Zhang. 2006. {``{Model selection in
nonparametric hazard regression}.''} \emph{Journal of Nonparametric
Statistics} 18 (7-8): 417--29.
\url{https://doi.org/10.1080/10485250601027042}.

\leavevmode\hypertarget{ref-Lian2013}{}%
Lian, Heng, Jianbo Li, and Yuao Hu. 2013. {``{Shrinkage variable
selection and estimation in proportional hazards models with additive
structure and high dimensionality}.''} \emph{Computational Statistics
and Data Analysis} 63: 99--112.
\url{https://doi.org/10.1016/j.csda.2013.02.003}.

\leavevmode\hypertarget{ref-Lin2013}{}%
Lin, Chen Yen, and Susan Halabi. 2013. {``{On model specification and
selection of the Cox proportional hazards model}.''} \emph{Statistics in
Medicine} 32 (26): 4609--23. \url{https://doi.org/10.1002/sim.5876}.

\leavevmode\hypertarget{ref-Yang2018}{}%
Yang, Guangren, Sumin Hou, Luheng Wang, and Yanqing Sun. 2018.
{``{Feature screening in ultrahigh-dimensional additive Cox model}.''}
\emph{Journal of Statistical Computation and Simulation} 88 (6):
1117--33. \url{https://doi.org/10.1080/00949655.2017.1422127}.

\end{CSLReferences}

\bibliographystyle{unsrt}
\bibliography{bibfile.bib}


\end{document}
