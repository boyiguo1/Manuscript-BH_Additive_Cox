\section{Simulation Studies}

In this section, we evaluate the prediction performance of the proposed Bayesian hierarchical additive model (BHAM) against three state-of-the-art additive Cox models, including mgcv \cite{Wood2017}, component selection and smoothing operator (COSSO) \cite{leng2006}, and adaptive COSSO \cite{storlie2011}. The mgcv model is the implementation of generalized additive models with automatic smoothing, one of the most popular methods to model nonlinear signals under the Cox proportional hazards framework. To note, mgcv doesn't support high-dimensional analysis and would not work in the $p>n$ scenario. The models COSSO and adaptive COSSO are designed to solve the nonlinear effect modelling in the high-dimensional setting. COSSO is one of the earliest additive model that leverage the sparsity-smoothness penalty, and adaptive COSSO improves COSSO by using adaptive weight for penalties aiming to relax from the uniform shrinkage applied to all additive functions. We also include the linear LASSO model as a benchmark, assessing the violation of linear assumption. The models are implemented with R packages \texttt{cosso} 2.1-1 \cite{R_cosso}, \texttt{mgcv} 1.8-31 \cite{R_mgcv}, and \texttt{glmnet} 4.1-3 \cite{simon2011} respectively. To make the evaluation fair, we control multiple implementation factors that could alter the performance, including the smoothing function and tuning of the models. We control the dimensionality of the smoothing functions to $K=10$ bases. We use the most popular cubic spline as the choice of smoothing function for mgcv and the proposed model. COSSO models do not provide any flexibility to define smooth functions, and hence use the default choice. We use 5-fold cross-validation to select the tuning parameter among 20 default candidates except \texttt{mgcv} which uses generalized cross-validation to select optimal model. The simulation study is conducted with R 4.1.0 on a high-performance 64-bit Linux platform with 48 cores of 2.70GHz eight-core Intel Xeon E5-2680 processors and 24G of RAM per core.

\subsection{Data Generating Process}

To established a comprehensive understanding of the methods performance, we consider multiple factors that are pivotal to high-dimensional data analysis, nonlinear modeling and survival outcomes. We examine different settings of signal sparsity (defined as the ratio of active variables and total number of covariates), sample size, correlation structure of the predictors, functional form of the underlying signals, and censoring rate.

To describe the data generating process, we generate a total of 1200 data points, where 200 serves as the training data and 1000 serves as the testing data. We consider the number of predictors $p$ to be {4, 10, 50, 100, 200} while limiting the number of active predictors to be 4. We simulate the predictors $\bs X$ from a multivariate normal distribution MVN$_{200\times p}(0, \Sigma)$. The variance covariance matrix $\Sigma$ follows a auto-regressive (AR) structure with two possible order parameters, $\rho \in \{0, 0.5\}$, where $AR(0)$ indicates the predictors are mutually independent. Among the all the predictors, we choose the first four to be active, in the forms of a quadratic function, an exponential function, a sine function and a linear function (see Figure \ref{fig:sim_fun}).
<!-- i.e. $B_1(x) = (5x-2)^2/20-3, B_2(x) = \exp(x+1)/10, B_3(x_3) = 2*sin(4x)$, and $B_4(x) = (1.4x+0.5)/2$.  -->
The rest of the predictors are inactive, i.e. $B_j(x) = 0$ for $j = 5, \dots, p.$ To simulate the survival response, we first generate the "true" survival time $T_i$ from a Weibull distribution with the scale parameter 1 and shape parameter 1.2 with the R package \texttt{simsurv} 1.0.0 \cite{R_simsurv}, accounting for the aforementioned nonlinear proportional hazards. We then generate the independent censoring time $C_i$ following a Weibull distribution with shape parameter 0.8. We use \cite{wan2016} to estimate the scale parameter of the censoring time distribution so that the censoring rate is controlled at {0.15, 0.3, 0.45}. To note, numeric problems can happen when estimating the scale parameter, where we use the median of other estimated scale parameters from the same simulation setting. The observed censored survival time is the minimum of the "true" survival and censoring time $t_i= min(T_i, C_i)$. The censoring indicator was set to be $I(C_i>T_i)$.

In each iteration of the simulation process, we independently generate the training and testing datasets following the previously described data generation process. We use the training dataset to construct each model of comparison and find the optimal model using 5-fold cross-validation. Then we use the fitted model to make predictions for the testing dataset and calculate the evaluation metrics, including deviance and C-index.

\subsection{Simulation Results}

Across all the simulation settings, the empirical censoring rate is controlled at the desired level (see Table \ref{tab:sim_cnr_prop}). As previously mentioned, mgcv doesn't fit model when the number of parameters exceeds the sample size, and hence ignored in $p = \{100,200\}$ evaluations. We also experience some programming errors when fitting COSSO and adaptive COSSO models when p is small. [TODO: add a sentence describing how much didn't finish, and direct to supporting information Table S2].  The proposed method, BHAM, is robust to programming errors in all examined settings. Our following performance evaluation of each method only use its successful runs.

Overall, we see consistent performance across different settings of dimensionality, censoring rate and correlation structure (see Figure \ref{fig:sim_cindex}): the proposed bamlasso model performs as good as, if not better than previous methods, including mgcv, COSSO, adaptive COSSO. The improvement is more substantial as p increases, or higher censoring rate, or when predictors are independent. As expected, adaptive COSSO performs slightly better than COSSO.
