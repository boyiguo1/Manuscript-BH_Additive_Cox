\section{Simulation Studies}
In this section, we evaluate the prediction performance of the propsoed model against three state-of-the-art methods for Cox additive models, mgcv, component selection and smoothing operator (COSSO), and adaptive COSSO. mgcv is the implementation of generalized additive models with automatic smoothing, and is the one of the most popular method to model nonlinear signals under the Cox proportional hazard framework. To note, mgcv doesn't support analyses when the number of parameters is larger than the sample size, and would not work in the $p>n$ scenario. COSSO and adaptive COSSO is designed to solve the nonlinear effect modelling in the high-dimensional setting. COSSO is one of the earliest additive model that leverage the sparsity-smoothness penalty, and adpative COSSO improves COSSO by using adaptive weight for penalties aiming to relax from the uniform shrinkage applied to all additive functions. The simulations are conducted with R 4.1.0 on a high-performance 64-bit Linux platform with 48 cores of 2.70GHz eight-core Intel Xeon E5-2680 processors and 24G of RAM per core. The three models of comparison are implemented with R packages \texttt{cosso} 2.1-1, and \texttt{mgcv} 1.8-31 respectively. To make the evaluation fair, we control multiple implementation factors that would alter the performance, including the smoothing function and tuning of the models. We control the dimensionality of the smoothing functions to 10 bases.  We use the most popular cubic spline as the choice of smoothing function for mgcv and the proposed model. COSSO models do not provide any felxibility to define smothing funcitons, and hence use the default choice [todo: add what it is]. We use 5-fold cross-validation to select the tuning parameter among 20 default candidates.


\subsection{Data Generating Process}
To established a comprehensive understanding of the methods performance, we consider multiple factors that are pivotal to high-dimensional data analysis, nonlinear modeling and survival outcomes. We consider the sparsity of the data defined as the ratio of active variables and total number of covariates, the sample size, correlation structure of the predictors, different functional form of the underlying signals (linear functions, sine function, quadrative function and exponential function), censoring rate.  

To describe the data generating process, we generate a total of 1200 data points, where 200 serves as the training data and 1000 serves as the testing data. We consider the number of predictors $p$ to be 4, 10, 50, 100, 200 while limiting the number of active predictors to be 4. We simulate the perdictors $\bs X$ from a multivariate normal distribution MVN$_{200\timesp}(0, \Sigma)$. We consider the variance covariance matrix $\Sigma$ to be auto-regressive (AR) with two parameter, 0 and 0.5, where $AR(0)$ represents the scenario where the predictors are mutually independent. Among the all the predcitors, we choose the first four to be the active predictors, i.e. $f(x_1) = (x+1)^2/5, f(x_2) = \exp(x+1)/25, f(x_3) = 3*sin(x)/2, and f_4(x_4) = (1.4*x+0.5)/2$. The rest of the predictors are inactive, i.e. $f(x_i) = 0$ for $i = 5, \dots, p.$ To simulate the the survival response, we first generate the "true" survival time $T_i$ for each individual from a Weibull distribution with the scale parameter 1 and shape parameter 1.2 [todo: list the distribution form with linear predictor] with the help of R package \textt{simsurv} 1.0.0. Meanwhile to control the censoring rate at 0.15, 0.3, 0.45, we generate the independent censoring time $C_i$ following a weibull distribution with shape parameter 0.8 and the scale parameter estimated using (Wan, F. (2017). Simulating survival data with predefined censoring rates for proportional hazards models. Statistics in medicine, 36(5), 838-854.). To note, there are cases that the estimation of the scale fails using the moethod due to numeric problems. For those iterations, we use median of previously estimated scale parameters of the same simulation setting. Please see the averaged censoring rate in the Supporting Information. The observed censored survival time is the minimum of the "true" survival and censoring time $t_i= min(T_i, C_i)$. The cenroing indicator $d_i$ was set to be $I(C_i>T_i)$.


[TODO: to talk about the iterations]

In each iteration of the simulation process, we independently generate the training and testing datasets following the previously described data generation process. We use the training dataset to construct each model of comparison and find the \`optimal\` model using 10-fold cross-validation. Then we use the fitted model to make prediction for the testing dataset and calculate the evaluation metrics.


[TODO: to talk about the predictoin performacne evaluations]

"Cross-validated Harrellâ€™s C-index (Harrell Jr et al. 1982, 1984, 1996) and Brier score (Brier 1950) are used as measures of predictive performance."

While the primary focus of the this simulation studies is to examine the predictive performance of the model, and hence, we select the followings as evaluation metrics:
- Discrimination: We use Uno etal's concordiance index. Even though Harrel's concordiance index is more popular, it suffers from bias when censoring presents.[Cite Rahman et al. 2017]


\subsection{Simulation Results}

### Algorithm Failures
before delving into the model performance evaluation, we would like to discuss the number of algorithm fails when runing simulations for the compared methods. Supplement Tab xx shows
* mgcv does not work for censarios where the number of coefficients is greater than the number sample size.
* cosso and acosso experienced programming failure particularlay when p is small. Please see appendix for the explaination and bug report.
* the proposed methods programming are robust in all conidtions.

In the following evaluation, we only summarize the performance from success runs.

### Deviance

```{r dvn_tab, results = "asis", eval = FALSE}
sim_test_tab[[1]] %>%
  xtable %>% 
  print(comment = FALSE)
```

```{r dvn_viz, eval = FALSE}
sim_test_viz[[1]]
```

### Cindex


```{r cdx_tab, results = "asis", eval = FALSE}
sim_test_tab[[2]] %>%
  xtable %>% 
  print(comment = FALSE)
```

```{r cdx_viz, eval = FALSE}
sim_test_viz[[2]] +
  ylim(c(0.5, 1))
```

