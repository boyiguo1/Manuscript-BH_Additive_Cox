\section{Introduction}

When the outcome of these data is right-censored time-to-event outcome, Cox proportional hazard model (Cox model hereafter) is one of the most popular analytic choices. Cox model describes the change of risk, modeled as hazard, on the multiplicative scale and provides easily interpretable insights in disease etiology. When a variable enters the Cox model as a predictors, an implicit assumption is imposed: the effect of the predictor are linear. The linear assumption is restrictive and doubtful in many case. A viable solution is to replace each variable with its functional form such that the modified Cox model retains its interpretability while gaining flexibility to model complex signals. The modified Cox model (hereafter referred to as additive Cox model) has many successful applications in biomedical research, for example, dose-response curve modeling \cite{Steenland2004}, yyy, zzz. To clarify, even both models involve using additive functions to flexibly model signals, additive Cox models are different from additive hazards models \cite{aalen1980}, mainly because they answer different scientific questions. Additive Cox models measure hazard change on the multiplicative scale and produce risk ratio interpretation, while additive hazards models measure hazard change on the additive scale and produce risk difference interpretation. In this manuscript, we limit our focus in the additive Cox models, and defer interested readers to \cite{lin1997} for a review of additive hazards models.

There are a wide range of options for additive functions. Among all the choices, one particular family stood out, splines. A spline is a piece-wise polynomial function with continuity conditions on the function and its derivatives at the points where the pieces join. \cite{Wood2017} It gains popularity in analytics since it's mathematically simple, smooth across the range, and hence easily interpretable. The application of spline in the Cox model is not complicated, simply replacing each predictor with the matrix form of the spline function. The estimation of coefficients follows the same procedure as fitting an ordinary Cox model. This approach is called regression spline. Nevertheless, when using many basis, regression spline can easily produce an overfitted model and the estimated functional form is very wiggly. To make data-driven decision on the functional form, smoothing penalty are applied, resulting the smoothing spline model \cite{reinsch1967}.

Large volume of biomedical data are generated in an exploding speed thanks to the recent advancements in technology. One particularly type of the large volume data is the high-dimensional data, where the number of predictors/dimensions is close if not more than the sample size ($p>>n$), commonly seen in -omics data and high-resolution image data. There are many efforts to extend Cox model to accommodate high-dimensional setting \cite{tibshirani1997, fan2002, zhang2007, wu2012, bradic2011, fan2010}, with a few allowing a small subset of predictors modelled nonparametric\cite{Leng2006, Du2010} (also known semiparmetric proportional hazard). These methods improve the flexibility of high-dimensional models, but still limit the number of predictors to be modeled nonlinearly to a very small number. The improvement of model flexibility offers limited utility when jointly signal structure of hundreds and thousands of biomarkers whose linearity are unknown, for example in genomics studies. We defer the review of high-dimensional Cox model to \cite{xu2012} and the triage of flexible Cox model in biomedical data analysis to \cite{Lin2013}.

The extension from semiparametric hazard to nonparametric hazard for Cox model in the high-dimensional setting is non-trivial. Specifically, how to decide if a function form of predictor should be included and what the appropriate form is extremely challenge as how to balance the signal sparsity and function smoothness is unclear.

a common practice: use group sparse penalties on the coefficients of smooth functions. Introduce excess shrinkage and produce overly smooth effect estimation.

\cite{Lian2013} proposed an high-dimensional additive Cox model that uses SCAD penalties to selecting non-parametric component functions. \cite{Yang2018} proposed the additive cox model specifically for high-dimensional data. Its primary aim is to screening the the predictors of the model. Bender, Groll, Scheipl (2018) proposed to model survival outcome with piece-wise exponential mdoels, which relies on transforming the survival outcome and fit a Poisson GLM. wu&witten2019 xxxx Given the well development of generalized additive model, this approach have wider utility, modeling nonlinear effects, and random effects. Challenges still exists when applying in high-deimensional data analysis, and computational efficiency compared to Cox model in most commonly used analytic cases. What is the problem here?

The main objectives of this project is to 1) expand current weaponary for non-linear effect modeling of time-to-event outcome via the bayesian hierarchical venue. Hence, we hypothesize that using Bayesian hierarhichy prior will improve the prediction performance for Cox additive model. Meanwhile, depending on the way we construct our basis matrix, as well as the prior set up, we can achieve an bi-level selection for the smoothing function. Here, we define the bi-level function as selection of the variable in the model, and selection of the linear versus non-linear effect of the variable.One of the critism that penalized model receive in the context of additive model is that the sparsity regularization will over smooth the the smoothing function by forceing many, and hence impact on the accuracy of the risk prediction. this phenomenon was previously observed in the context of generalized linear mel.

To the best of knowledge, there is no efforts on studying bayesian heiarchical models, particularaly the spike-and-slab lasso prior under the high-dimensional additive model under Cox proportional hazard paradigm. Where there are tremendous amount of literature that explored Bayesian regularized model for modeling continuous or binary outcome in the context of additive models, there are limited Bayesian models to model survival outcomes as far of our knowledge. We are the first to apply spike-and-slab prior on Cox additive model for the purpose of survival prediction and functional selection in the context of high-dimensional cox model. We see a broad range of applications in precision medicine research, particularly genomics data analysis. [A sentence about the R package]
