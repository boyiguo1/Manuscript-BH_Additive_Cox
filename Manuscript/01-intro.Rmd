\section{Introduction}

When the outcome of these data is right-censored time-to-event outcome, Cox proportional hazard model (Cox model hereafter) is one of the most popular analytic choices. Cox model describes the change of risk, modeled as hazard, on the multiplicative scale and provides easily interpretable insights in disease etiology. When a variable enters the Cox model as a predictors, an implicit assumption is imposed: the effect of the predictor are linear. The linear assumption is restrictive and doubtful in many case. A viable solution is to replace each variable with its functional form such that the modified Cox model retains its interpretability while gaining flexibility to model complex signals. The modified Cox model (hereafter referred to as additive Cox model) has many successful applications in biomedical research, for example, dose-response curve modeling \cite{Steenland2004}, yyy, zzz. To clarify, even both models involve using additive functions to flexibly model signals, additive Cox models are different from additive hazards models \cite{aalen1980}, mainly because they answer different scientific questions. Additive Cox models measure hazard change on the multiplicative scale and produce risk ratio interpretation, while additive hazards models measure hazard change on the additive scale and produce risk difference interpretation. In this manuscript, we limit our focus in the additive Cox models, and defer interested readers to \cite{lin1997} for a review of additive hazards models.

There are a wide range of options for additive functions. Among all the choices, one particular family stood out, splines. A spline is a piece-wise polynomial function with continuity conditions on the function and its derivatives at the points where the pieces join. \cite{Wood2017} It gains popularity in analytics since it's mathematically simple, smooth across the range, and hence easily interpretable. The application of spline in the Cox model is not complicated, simply replacing each predictor with the matrix form of the spline function. The estimation of coefficients follows the same procedure as fitting an ordinary Cox model. This approach is called regression spline. Nevertheless, when using many basis, regression spline can easily produce an overfitted model and the estimated functional form is very wiggly. To make data-driven decision on the functional form, smoothing penalty are applied, resulting the smoothing spline model \cite{reinsch1967}.

Large volume of biomedical data are generated in an exploding speed thanks to the recent advancements in technology. One particularly type of the large volume data is the high-dimensional data, where the number of predictors/dimensions is close if not more than the sample size ($p>>n$), commonly seen in -omics data and high-resolution image data. There are many efforts to extend Cox model to accommodate high-dimensional setting \cite{tibshirani1997, fan2002, zhang2007, wu2012, bradic2011, fan2010}, with a few allowing a small subset of predictors modelled nonparametric\cite{Leng2006, Du2010} (also known semiparmetric proportional hazard). These methods improve the flexibility of high-dimensional models, but still limit the number of predictors to be modeled nonlinearly to a very small number. The improvement of model flexibility offers limited utility when jointly signal structure of hundreds and thousands of biomarkers whose linearity are unknown, for example in genomics studies. We defer the review of high-dimensional Cox model to \cite{xu2012} and the triage of flexible Cox model in biomedical data analysis to \cite{Lin2013}.

The extension from semiparametric hazard to nonparametric hazard for Cox model in the high-dimensional setting is non-trivial. Specifically, how to decide if a function form of predictor should be included and what the appropriate form is extremely challenge as how to balance the signal sparsity and function smoothness is unclear. One naive approach to fit high-dimensional additive Cox model is to employ group sparse penalty on the coefficients of smooth functions. \cite{Lian2013} proposed an high-dimensional additive Cox model that uses SCAD penalties to selecting non-parametric component functions. \cite{Yang2018} proposed a feature screening procedure for the additive cox model in high-dimensional data analysis; however, the method contribute to risk prediction directly. Nevertheless, the application of sparsity penalty without accounting function smoothness is not recommended in the generalized additive model literature, as the approach is inclined to produce wiggle estimation when underlying signal is smooth. \cite{Meier2009} In addition, most of these penalized model relies on a global penalty ignoring each additive components can have different degree of smoothness, and hence introduce an oversmoothed solution. \cite{scheipl2013} There are also other approaches provides flexible solutions to model survival outcome in the high-dimensional setting. \cite{bender2018} proposed to model survival outcome with piece-wise exponential models, which is based on the idea of transforming the survival outcome and fit a Poisson GLM. Nevertheless, this approach is less computationally efficient and vulnerable to convergence problem due to the numeric calculations. \cite{wu2019} extended the trend filtering model to the survival setting. Nevertheless, the solution is a series of step functions, which would not be optimal if underlying functions are assumed to be smooth.

To address this shortcomings, we extend the Bayesian hierarchical additive model (BHAM) from the generalized regression setting to the survival setting.

[TODO: add a sentences describe the previous achievement of BHAM in GAM literature.]

The main contribution of BHAM is three-folded, 1) a two-part spike-and-slab LASSO prior for smoothing function to achieve adequate smoothing while considering sparsity of the signals; 2) it provides simultaneous outcome prediction and a bi-level functional selection; 3) a scalable EM-Coordinate Descent algorithm for model fitting to relief the model fitting from computationally prohibitive Monte Carlo Markov Chain algorithms. Here, we define the bi-level function as selection of the variable in the model, and selection of the linear versus non-linear effect of the variable. To the best of knowledge, we are the first to apply spike-and-slab LASSO prior in the context of high-dimensional Cox additive model for the purposes of simultaneous survival prediction and functional selection. We see a broad range of applications in precision medicine research, particularly genomics data analysis. The implementation of the proposed model is freely available via \url{https://github.com/boyiguo1/BHAM}
