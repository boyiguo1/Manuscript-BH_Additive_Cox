@article{Lian2013,
abstract = {Variable selection and estimation in proportional hazards models with additive relative risk is considered. Both objectives are achieved using a penalized partial likelihood with a group nonconcave penalty. Oracle properties of the estimator are demonstrated, when the dimensionality is allowed to be larger than sample size. To deal with the computational challenges when p>n, an active-set-type algorithm is proposed. Finally, the method is illustrated with simulation examples and a real microarray study. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Lian, Heng and Li, Jianbo and Hu, Yuao},
doi = {10.1016/j.csda.2013.02.003},
file = {:C\:/Users/boyiguo1/Desktop/1-s2.0-S0167947313000479-main.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {(Extended) Bayesian information criterion,Akaike information criterion,Polynomial splines,Proportional hazards models},
pages = {99--112},
publisher = {Elsevier B.V.},
title = {{Shrinkage variable selection and estimation in proportional hazards models with additive structure and high dimensionality}},
url = {http://dx.doi.org/10.1016/j.csda.2013.02.003},
volume = {63},
year = {2013}
}


@article{Leng2006,
abstract = {We propose a novel model selection method for a nonparametric extension of the Cox proportional hazard model, in the framework of smoothing splines ANOVA models. The method automates the model building and model selection processes simultaneously by penalizing the reproducing kernel Hilbert space norms. On the basis of a reformulation of the penalized partial likelihood, we propose an efficient algorithm to compute the estimate. The solution demonstrates great flexibility and easy interpretability in modeling relative risk functions for censored data. Adaptive choice of the smoothing parameter is discussed. Both simulations and a real example suggest that our proposal is a useful tool for multivariate function estimation and model selection in survival analysis.},
author = {Leng, Chenlei and Zhang, Hao Helen},
doi = {10.1080/10485250601027042},
file = {:C\:/Users/boyiguo1/Desktop/MSNHR.pdf:pdf},
issn = {10485252},
journal = {Journal of Nonparametric Statistics},
keywords = {COSSO,Cox proportional hazard model,Model selection,Penalized likelihood},
number = {7-8},
pages = {417--429},
title = {{Model selection in nonparametric hazard regression}},
volume = {18},
year = {2006}
}

@article{Du2010,
abstract = {We study the Cox models with semiparametric relative risk, which can be partially linear with one nonparametric component, or multiple additive or nonadditive nonparametric components. A penalized partial likelihood procedure is proposed to simultaneously estimate the parameters and select variables for both the parametric and the nonparametric parts. Two penalties are applied sequentially. The first penalty, governing the smoothness of the multivariate nonlinear covariate effect function, provides a smoothing spline ANOVA framework that is exploited to derive an empirical model selection tool for the nonparametric part. The second penalty, either the smoothlyclipped-absolute- deviation (SCAD) penalty or the adaptive LASSO penalty, achieves variable selection in the parametric part. We show that the resulting estimator of the parametric part possesses the oracle property, and that the estimator of the nonparametric part achieves the optimal rate of convergence. The proposed procedures are shown to work well in simulation experiments, and then applied to a real data example on sexually transmitted diseases. {\textcopyright} Institute of Mathematical Statistics, 2010.},
author = {Du, Pang and Ma, Shuangge and Liang, Hua},
doi = {10.1214/09-AOS780},
file = {:C\:/Users/boyiguo1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Ma, Liang - 2010 - Penalized variable selection procedure for Cox models with semiparametric relative risk.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Backfitting,Partially linear models,Penalized partial likelihood,Penalized variable selection,Proportional hazards,Smoothing spline ANOVA},
number = {4},
pages = {2092--2117},
title = {{Penalized variable selection procedure for Cox models with semiparametric relative risk}},
volume = {38},
year = {2010}
}

@article{Yang2018,
abstract = {file:///C:/Users/Marika/Desktop/universit{\`{a}} di pavia/articoli/strategie per l'infertilit{\`{a}}/nihms964087.pdf},
author = {Yang, Guangren and Hou, Sumin and Wang, Luheng and Sun, Yanqing},
doi = {10.1080/00949655.2017.1422127},
file = {:C\:/Users/boyiguo1/Desktop/nihms-1048619.pdf:pdf},
isbn = {2163684814},
issn = {0094-9655},
journal = {Journal of Statistical Computation and Simulation},
keywords = {determination,protein crystallography,protein data bank,r -factor,resolution,restraints,structure,structure interpretation,structure quality,structure refinement,structure validation},
month = {apr},
number = {6},
pages = {1117--1133},
title = {{Feature screening in ultrahigh-dimensional additive Cox model}},
url = {https://www.tandfonline.com/doi/full/10.1080/00949655.2017.1422127},
volume = {88},
year = {2018}
}


@article{Lin2013,
abstract = {Prognosis plays a pivotal role in patient management and trial design. A useful prognostic model should correctly identify important risk factors and estimate their effects. In this article, we discuss several challenges in selecting prognostic factors and estimating their effects using the Cox proportional hazards model. Although a flexible semiparametric form, the Cox's model is not entirely exempt from model misspecification. To minimize possible misspecification, instead of imposing traditional linear assumption, flexible modeling techniques have been proposed to accommodate the nonlinear effect. We first review several existing nonparametric estimation and selection procedures and then present a numerical study to compare the performance between parametric and nonparametric procedures. We demonstrate the impact of model misspecification on variable selection and model prediction using a simulation study and an example from a phase III trial in prostate cancer. {\textcopyright} 2013 John Wiley & Sons, Ltd. {\textcopyright} 2013 John Wiley & Sons, Ltd.},
author = {Lin, Chen Yen and Halabi, Susan},
doi = {10.1002/sim.5876},
file = {:C\:/Users/boyiguo1/Desktop/sim.5876.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {COSSO,Cox model,LASSO,Model selection,Smoothing splines},
number = {26},
pages = {4609--4623},
pmid = {23784939},
title = {{On model specification and selection of the Cox proportional hazards model}},
volume = {32},
year = {2013}
}

@book{Wood2017,
  title={Generalized additive models: an introduction with R},
  author={Wood, Simon N},
  year={2017},
  publisher={CRC press}
}

@article{Marra2011,
  title={Practical variable selection for generalized additive models},
  author={Marra, Giampiero and Wood, Simon N},
  journal={Computational Statistics \& Data Analysis},
  volume={55},
  number={7},
  pages={2372--2387},
  year={2011},
  publisher={Elsevier}
}


@article{Efron1977,
abstract = {D.R. Cox has suggested a simple method for the regression analysis of censored data. We carry out an information calculation which shows that Cox's method has full asymptotic efficiency under conditions which are likely to be satisfied in many realistic situations. The connection of Cox's method with the Kaplan-Meier estimator of a survival curve is made explicit. {\textcopyright} 1977, Taylor {\&} Francis Group, LLC.},
author = {Efron, Bradley},
doi = {10.1080/01621459.1977.10480613},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Censored data,Cox likelihood,Survival curves},
title = {{The efficiency of cox's likelihood function for censored data}},
year = {1977}
}

@article{Govindarajulu2007,
abstract = {The additive hazards model is one of the most commonly used regression models in the analysis of failure time data and many methods have been developed for its inference under various situations. This paper discusses the situation where one faces current status data and also there exists informative censoring or when the failure time of interest and the observation process are correlated. Several authors have discussed the problem and in particular, Zhang et al. (2005) and Zhao et al. (2015) proposed an estimating equationbased approach and a copula model-based method, respectively. However, the former may not be efficient and the latter needs some restrictive assumptions. To address these, we propose a sieve maximum likelihood estimation approach that can be more efficient and also does not require the assumption above. For the implementation of the method, an EM algorithm is developed and the asymptotic properties of the resulting estimators are established. The numerical results suggest that the proposed method works well in practical situations and an application is provided.},
author = {Govindarajulu, Usha S. and Spiegelman, Donna and Thurston, Sally W. and Ganguli, Bhaswati and Eisen, Ellen A.},
doi = {10.1002/sim.2848},
file = {:C$\backslash$:/Users/boyiguo1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Govindarajulu et al. - 2007 - Comparing smoothing techniques in Cox models for exposure–response relationships.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {publication bias,selection bias,selection model,sensitivity analysis,unpublished studies},
month = {sep},
number = {20},
pages = {3735--3752},
title = {{Comparing smoothing techniques in Cox models for exposure–response relationships}},
url = {http://doi.wiley.com/10.1002/sim.2848},
volume = {26},
year = {2007}
}

@article{Govindarajulu2009,
abstract = {We examined the behavior of alternative smoothing methods for modeling environmental epidemiology data. Model fit can only be examined when the true exposure-response curve is known and so we used simulation studies to examine the performance of penalized splines (P-splines), restricted cubic splines (RCS), natural splines (NS), and fractional polynomials (FP). Survival data were generated under six plausible exposure-response scenarios with a right skewed exposure distribution, typical of environmental exposures. Cox models with each spline or FP were fit to simulated datasets. The best models, e.g. degrees of freedom, were selected using default criteria for each method. The root mean-square error (rMSE) and area difference were computed to assess model fit and bias (difference between the observed and true curves). The test for linearity was a measure of sensitivity and the test of the null was an assessment of statistical power. No one method performed best according to all four measures of performance, however, all methods performed reasonably well. The model fit was best for P-splines for almost all true positive scenarios, although fractional polynomials and RCS were least biased, on average. Copyright {\textcopyright}2009 The Berkeley Electronic Press. All rights reserved.},
author = {Govindarajulu, Usha S. and Malloy, Elizabeth J. and Ganguli, Bhaswati and Spiegelman, Donna and Eisen, Ellen A.},
doi = {10.2202/1557-4679.1104},
file = {:C$\backslash$:/Users/boyiguo1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Govindarajulu et al. - 2009 - The comparison of alternative smoothing methods for fitting non-linear exposure-response relationships wit.pdf:pdf},
issn = {15574679},
journal = {International Journal of Biostatistics},
keywords = {Cox model,Fractional polynomial,Natural spline,Penalized spline,Restricted cubic spline,Simulation},
number = {1},
pmid = {20231865},
title = {{The comparison of alternative smoothing methods for fitting non-linear exposure-response relationships with Cox models in a simulation study}},
volume = {5},
year = {2009}
}

@article{Gray1992,
abstract = {In this article some flexible methods for modeling censored survival data using splines are applied to the problem of modeling the time to recurrence of breast cancer patients. The basic idea is to use fixed knot splines with a fairly modest number of knots to model aspects of the data, and then to use penalized partial likelihood to estimate the parameters of the model. Test statistics are proposed which are analogs of those used in traditional likelihood analysis, and approximations to the distributions of these statistics are suggested. In an analysis of a large data set taken from clinical trials conducted by the Eastern Cooperative Oncology Group, these methods are seen to give useful insight into how prognosis varies as a function of continuous covariates, and also into how covariate effects change with follow-up time. {\textcopyright} 1992 Taylor {\&} Francis Group, LLC.},
author = {Gray, Robert J.},
doi = {10.1080/01621459.1992.10476248},
file = {:C$\backslash$:/Users/boyiguo1/Desktop/2290630.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Breast cancer,Censored data,Penalized likelihood,Proportional hazards,Splines},
month = {dec},
number = {420},
pages = {942--951},
title = {{Flexible Methods for Analyzing Survival Data Using Splines, with Applications to Breast Cancer Prognosis}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1992.10476248},
volume = {87},
year = {1992}
}

@article{Marra2021,
abstract = {The majority of methods available to model survival data only deal with right censoring. However, there are many applications where left, right and/or interval censoring simultaneously occur. A methodology that is capable of handling all types of censoring as well as flexibly estimating several types of covariate effects is presented. The baseline hazard is modelled through monotonic P-splines. The model's parameters are estimated using an efficient and stable penalised likelihood algorithm. The proposed framework is evaluated in simulation, and illustrated using an original data example on time to first hospital infection or in-hospital death in cirrhotic patients. A peak of risk in the first week since hospitalisation is identified, together with a non-linear effect of Model for End-Stage Liver Disease (MELD) score. The GJRM R package, with an implementation of our approach, is freely available on CRAN.},
author = {Marra, Giampiero and Farcomeni, Alessio and Radice, Rosalba},
doi = {10.1016/j.csda.2020.107092},
file = {:Users/boyiguo/Downloads/1-s2.0-S0167947320301833-main.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics & Data Analysis},
keywords = {Additive predictor,Link function,Mixed censoring,Penalised log-likelihood,Regression splines,Survival data},
month = {mar},
pages = {107092},
publisher = {Elsevier B.V.},
title = {{Link-based survival additive models under mixed censoring to assess risks of hospital-acquired infections}},
url = {https://doi.org/10.1016/j.csda.2020.107092 https://linkinghub.elsevier.com/retrieve/pii/S0167947320301833},
volume = {155},
year = {2021}
}

@article{Ibrahim2001,
abstract = {We propose methods for Bayesian inference for a new class of semiparametric survival models with a cure fraction. Specifically, we propose a semiparametric cure rate model with a smoothing parameter that controls the degree of parametricity in the right tail of the survival distribution. We show that such a parameter is crucial for these kinds of models and can have an impact on the posterior estimates. Several novel properties of the proposed model are derived. In addition, we propose a class of improper noninformative priors based on this model and examine the properties of the implied posterior. Also, a class of informative priors based on historical data is proposed and its theoretical properties are investigated. A case study involving a melanoma clinical trial is discussed in detail to demonstrate the proposed methodology.},
author = {Ibrahim, Joseph G. and Chen, Ming Hui and Sinha, Debajyoti},
doi = {10.1111/j.0006-341X.2001.00383.x},
issn = {0006341X},
journal = {Biometrics},
keywords = {Cure rate model,Gibbs sampling,Historical data,Latent variables,Piecewise exponential,Posterior distribution,Semiparametric model,Smoothing parameter},
pmid = {11414560},
title = {{Bayesian semiparametric models for survival data with a cure fraction}},
year = {2001}
}
@book{Klein2003,
abstract = {Applied statisticians in many fields must frequently analyze time to event data. While the statistical tools presented in this book are applicable to data from medicine, biology, public health, epidemiology, engineering, economics, and demography, the focus here is on applications of the techniques to biology and medicine. The analysis of survival experiments is complicated by issues of censoring, where an individual{\&}apos;s life length is known to occur only in a certain period of time, and by truncation, where individuals enter the study only if they survive a sufficient length of time or individuals are included in the study only if the event has occurred by a given date. The use of counting process methodology has allowed for substantial advances in the statistical theory to account for censoring and truncation in survival experiments. This book makes these complex methods more accessible to applied researchers without an advanced mathematical background. The authors present the essence of these techniques, as well as classical techniques not based on counting processes, and apply them to data. Practical suggestions for implementing the various methods are set off in a series of Practical Notes at the end of each section. Technical details of the derivation of the techniques are sketched in a series of Technical Notes. This book will be useful for investigators who need to analyze censored or truncated life time data, and as a textbook for a graduate course in survival analysis. The prerequisite is a standard course in statistical methodology.},
address = {New York, NY},
author = {Klein, John P. and Moeschberger, Melvin L.},
booktitle = {Pharmaceutical Statistics},
doi = {10.1007/b97377},
isbn = {978-0-387-95399-1},
issn = {1539-1604},
publisher = {Springer New York},
series = {Statistics for Biology and Health},
title = {{Survival Analysis}},
url = {http://link.springer.com/10.1007/b97377},
year = {2003}
}


@article{Steenland2004,
abstract = {Dose-response modeling in occupational epidemiology is usually motivated by questions of causal inference (eg, is there a monotonic increase of risk with increasing exposure?) or risk assessment (eg, how much excess risk exists at any given level of exposure?). We focus on several approaches to dose-response in occupational cohort studies. Categorical analyses are useful for detecting the shape of dose-response. However, they depend on the number and location of cutpoints and result in step functions rather than smooth curves. Restricted cubic splines and penalized splines are useful parametric techniques that provide smooth curves. Although splines can complement categorical analyses, they do not provide interpretable parameters. The shapes of these curves will depend on the degree of "smoothing" chosen by the analyst. We recommend combining categorical analyses and some type of smoother, with the goal of developing a reasonably simple parametric model. A simple parametric model should serve as the goal of dose-response analyses because (1) most "true" exposure response curves in nature may be reasonably simple, (2) a simple parametric model is easily communicated and used by others, and (3) a simple parametric model is the best tool for risk assessors and regulators seeking to estimate individual excess risks per unit of exposure. We discuss these issues and others, including whether the best model is always the one that fits the best, reasons to prefer a linear model for risk in the low-exposure region when conducting risk assessment, and common methods of calculating excess lifetime risk at a given exposure from epidemiologic results (eg, from rate ratios). Points are illustrated using data from a study of dioxin and cancer. Copyright {\textcopyright} 2003 by Lippincott Williams {\&} Wilkins.},
annote = {Gread review article. Have a lot of epidemology perspective on using spline},
author = {Steenland, Kyle and Deddens, James A.},
doi = {10.1097/01.ede.0000100287.45004.e7},
file = {:C$\backslash$:/Users/boyiguo1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steenland, Deddens - 2004 - A practical guide to dose-response analyses and risk assessment in occupational epidemiology(2).pdf:pdf},
issn = {10443983},
journal = {Epidemiology},
number = {1},
pages = {63--70},
pmid = {14712148},
title = {{A practical guide to dose-response analyses and risk assessment in occupational epidemiology}},
volume = {15},
year = {2004}
}


@incollection{aalen1980,
  title={A model for nonparametric regression analysis of counting processes},
  author={Aalen, Odd},
  booktitle={Mathematical statistics and probability theory},
  pages={1--25},
  year={1980},
  publisher={Springer}
}

@inbook{lin1997,
	title = {Additive Hazards Regression Models for Survival Data},
	author = {Lin, D. Y. and Ying, Zhiliang},
	year = {1997},
	date = {1997},
	publisher = {Springer US},
	pages = {185--198},
	doi = {10.1007/978-1-4684-6316-3_10},
	url = {http://dx.doi.org/10.1007/978-1-4684-6316-3_10}
}

@article{reinsch1967,
author = {Reinsch, Ch. H.},
journal = {Numerische Mathematik},
keywords = {numerical analysis},
pages = {177-183},
title = {Smoothing by Spline Functions.},
url = {http://eudml.org/doc/131782},
volume = {10},
year = {1967},
}

@article{tibshirani1997,
	title = {THE LASSO METHOD FOR VARIABLE SELECTION IN THE COX MODEL},
	author = {TIBSHIRANI, ROBERT},
	year = {1997},
	month = {02},
	date = {1997-02-28},
	journal = {Statistics in Medicine},
	pages = {385--395},
	volume = {16},
	number = {4},
	doi = {10.1002/(sici)1097-0258(19970228)16:4<385::aid-sim380>3.0.co;2-3},
	url = {http://dx.doi.org/10.1002/(sici)1097-0258(19970228)16:4<385::aid-sim380>3.0.co;2-3},
	langid = {en}
}

@article{fan2002,
	title = {Variable Selection for Cox's proportional Hazards Model and Frailty Model},
	author = {Fan, Jianqing and Li, Runze},
	year = {2002},
	month = {02},
	date = {2002-02-01},
	journal = {The Annals of Statistics},
	volume = {30},
	number = {1},
	doi = {10.1214/aos/1015362185},
	url = {http://dx.doi.org/10.1214/aos/1015362185}
}

@article{zhang2007,
	title = {Adaptive Lasso for Cox's proportional hazards model},
	author = {Zhang, H. H. and Lu, W.},
	year = {2007},
	month = {08},
	date = {2007-08-05},
	journal = {Biometrika},
	pages = {691--703},
	volume = {94},
	number = {3},
	doi = {10.1093/biomet/asm037},
	url = {http://dx.doi.org/10.1093/biomet/asm037},
	langid = {en}
}

@article{wu2012,
	title = {Elastic net for Cox{\textquoteright}s proportional hazards model with a solution path algorithm},
	author = {Wu, Yichao},
	year = {2012},
	month = {01},
	date = {2012-01},
	journal = {Statistica Sinica},
	volume = {22},
	number = {1},
	doi = {10.5705/ss.2010.107},
	url = {http://dx.doi.org/10.5705/ss.2010.107}
}

@article{bradic2011,
	title = {Regularization for Cox{\textquoteright}s proportional hazards model with NP-dimensionality},
	author = {Bradic, Jelena and Fan, Jianqing and Jiang, Jiancheng},
	year = {2011},
	month = {12},
	date = {2011-12-01},
	journal = {The Annals of Statistics},
	volume = {39},
	number = {6},
	doi = {10.1214/11-aos911},
	url = {http://dx.doi.org/10.1214/11-aos911}
}

@inbook{fan2010,
	title = {High-dimensional variable selection for Cox{\textquoteright}s proportional hazards model},
	author = {Fan, Jianqing and Feng, Yang and Wu, Yichao},
	year = {2010},
	date = {2010},
	publisher = {Institute of Mathematical Statistics},
	pages = {70--86},
	doi = {10.1214/10-imscoll606},
	url = {http://dx.doi.org/10.1214/10-imscoll606}
}


@article{xu2012,
	title = {High-Dimensional Cox Regression Analysis in Genetic Studies with Censored Survival Outcomes},
	author = {Xu, Jinfeng},
	year = {2012},
	date = {2012},
	journal = {Journal of Probability and Statistics},
	pages = {1--14},
	volume = {2012},
	doi = {10.1155/2012/478680},
	url = {http://www.hindawi.com/journals/jps/2012/478680/},
	langid = {en}
}


@article{cox1972,
	title = {Regression Models and Life-Tables},
	author = {Cox, D. R.},
	year = {1972},
	date = {1972},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	pages = {187--202},
	volume = {34},
	number = {2},
	doi = {10.1111/j.2517-6161.1972.tb00899.x},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1972.tb00899.x},
	note = {{\_}eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1972.tb00899.x},
	langid = {en}
}

@article{breslow1974,
	title = {Covariance Analysis of Censored Survival Data},
	author = {Breslow, N.},
	year = {1974},
	month = {03},
	date = {1974-03},
	journal = {Biometrics},
	pages = {89},
	volume = {30},
	number = {1},
	doi = {10.2307/2529620},
	url = {https://www.jstor.org/stable/2529620?origin=crossref},
	langid = {en}
}


@article{bender2018,
	title = {A generalized additive model approach to time-to-event analysis},
	author = {Bender, Andreas and Groll, Andreas and Scheipl, Fabian},
	year = {2018},
	month = {06},
	date = {2018-06-01},
	journal = {Statistical Modelling},
	pages = {299--321},
	volume = {18},
	number = {3-4},
	doi = {10.1177/1471082X17748083},
	url = {https://doi.org/10.1177/1471082X17748083},
	note = {Publisher: SAGE Publications India},
	langid = {en}
}

@article{wu2019,
	title = {Flexible and Interpretable Models for Survival Data},
	author = {Wu, Jiacheng and Witten, Daniela},
	year = {2019},
	date = {2019},
	journal = {Journal of computational and graphical statistics : a joint publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America},
	pages = {954--966},
	volume = {28},
	number = {4},
	doi = {10.1080/10618600.2019.1592758},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7377334/},
	note = {PMID: 32704224
PMCID: PMC7377334}
}

@article{tang2019,
	title = {Gsslasso Cox: a Bayesian hierarchical model for predicting survival and detecting associated genes by incorporating pathway information},
	author = {Tang, Zaixiang and Lei, Shufeng and Zhang, Xinyan and Yi, Zixuan and Guo, Boyi and Chen, Jake Y. and Shen, Yueping and Yi, Nengjun},
	year = {2019},
	month = {12},
	date = {2019-12},
	journal = {BMC Bioinformatics},
	pages = {94},
	volume = {20},
	number = {1},
	doi = {10.1186/s12859-019-2656-1},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2656-1},
	langid = {en}
}

@article{guo2022,
	title = {Spike-and-Slab LASSO Generalized Additive Models and Scalable Algorithms for High-Dimensional Data Analysis},
	author = {Guo, Boyi and Jaeger, Byron C. and Rahman, A. K. M. Fazlur and Long, D. Leann and Yi, Nengjun},
	year = {2022},
	month = {04},
	date = {2022-04-10},
	journal = {arXiv:2110.14449 [stat]},
	url = {http://arxiv.org/abs/2110.14449},
	note = {arXiv: 2110.14449}
}

@article{rockova2018a,
	title = {Bayesian estimation of sparse signals with a continuous spike-and-slab prior},
	author = {{Ro{\v{c}}ková}, Veronika},
	year = {2018},
	month = {02},
	date = {2018-02},
	journal = {The Annals of Statistics},
	pages = {401--437},
	volume = {46},
	number = {1},
	doi = {10.1214/17-AOS1554},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-46/issue-1/Bayesian-estimation-of-sparse-signals-with-a-continuous-spike-and/10.1214/17-AOS1554.full},
	note = {Publisher: Institute of Mathematical Statistics}
}

@article{rockova2018b,
	title = {The Spike-and-Slab LASSO},
	author = {{Ro{\v{c}}ková}, Veronika and George, Edward I.},
	year = {2018},
	month = {01},
	date = {2018-01-02},
	journal = {Journal of the American Statistical Association},
	pages = {431--444},
	volume = {113},
	number = {521},
	doi = {10.1080/01621459.2016.1260469},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1260469},
	langid = {en}
}

@article{tang2018,
	title = {Group spike-and-slab lasso generalized linear models for disease prediction and associated genes detection by incorporating pathway information},
	author = {Tang, Zaixiang and Shen, Yueping and Li, Yan and Zhang, Xinyan and Wen, Jia and Qian, {Chen{\textquoteright}ao} and Zhuang, Wenzhuo and Shi, Xinghua and Yi, Nengjun},
	editor = {Hancock, John},
	year = {2018},
	month = {03},
	date = {2018-03-15},
	journal = {Bioinformatics},
	pages = {901--910},
	volume = {34},
	number = {6},
	doi = {10.1093/bioinformatics/btx684},
	url = {https://academic.oup.com/bioinformatics/article/34/6/901/4565593},
	langid = {en}
}

@article{scheipl2013,
	title = {Penalized likelihood and Bayesian function selection in regression models},
	author = {Scheipl, Fabian and Kneib, Thomas and Fahrmeir, Ludwig},
	year = {2013},
	month = {10},
	date = {2013-10},
	journal = {AStA Advances in Statistical Analysis},
	pages = {349--385},
	volume = {97},
	number = {4},
	doi = {10.1007/s10182-013-0211-3},
	url = {http://link.springer.com/10.1007/s10182-013-0211-3},
	langid = {en}
}

@article{Meier2009,
abstract = {We propose a new sparsity-smoothness penalty for high-dimensional generalized additive models. The combination of sparsity and smoothness is crucial for mathematical theory as well as performance for finite-sample data. We present a computationally efficient algorithm, with provable numerical convergence properties, for optimizing the penalized likelihood. Furthermore, we provide oracle results which yield asymptotic optimality of our estimator for high dimensional but sparse additive models. Finally, an adaptive version of our sparsity-smoothness penalized approach yields large additional performance gains. {\textcopyright} Institute of Mathematical Statistics, 2009.},
archivePrefix = {arXiv},
arxivId = {0806.4115},
author = {Meier, Lukas and {Van De Geer}, Sara and B{\"{u}}hlmann, Peter},
doi = {10.1214/09-AOS692},
eprint = {0806.4115},
file = {:C\:/Users/boyiguo1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meier, Van De Geer, B{\"{u}}hlmann - 2009 - High-dimensional additive modeling.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Group lasso,Model selection,Nonparametric regression,Oracle inequality,Penalized likelihood,Sparsity},
number = {6 B},
pages = {3779--3821},
title = {{High-dimensional additive modeling}},
volume = {37},
year = {2009}
}

@incollection{chipman2006,
  title={Prior distributions for Bayesian analysis of screening experiments},
  author={Chipman, Hugh},
  booktitle={Screening},
  pages={236--267},
  year={2006},
  publisher={Springer}
}

